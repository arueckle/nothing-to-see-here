model_name: bert-base-uncased
model_type: bert
type: text_task
task: sentiment
subtask: sst
config:
  using: pfeiffer
description: |
  Sentiment task adapter for bert-base-uncased in Pfeiffer architecture, trained on SST-2.
author: calpt
email: "calpt@mail.de"
url: "https://github.com/calpt"

default_version: "2"
files:
  - version: "2"
    sha1: "7473209089242e423b1f0a9d8c7ba9272b6519b2"
    sha256: "4432b9559e2f41337d52005e7b41c1c6a675e811f5eaea4411b6c769c2b2ea93"
    url: "https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/mrpc/bert-base-uncased/pfeiffer/mrpc.zip"

citation: |
  @misc{pfeiffer2020adapterfusion,
    title={AdapterFusion: Non-Destructive Task Composition for Transfer Learning},
    author={Jonas Pfeiffer and Aishwarya Kamath and Andreas Rücklé and Kyunghyun Cho and Iryna Gurevych},
    year={2020},
    eprint={2005.00247},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
  }

